general:
  label_type: &label_type isup
  number_of_classes: &n_classes 6
  seed: &seed 8556
  image_channels: &img_channels 3
  client_names: ['client1']
  folder: 'testdata/data'

# ------  ------  ------  ------  ------  ------  ------

data_generation:
  cache: #
  # CSV FILES
  train_batch_size: 16
  valid_batch_size: 16
  # WHERE TO FIND INFORMATION IN CSV FILE AND WHAT INFORMATION TO USE
  annotation_column: isup # column of the main class label, as it is called in csv file (isup, bin, relapse_time)
  additional_columns: # list of dict with
    # - internal_column_name: ['name_of_column_in_csv', 'input'] if used as additional input (like binary prediction)
    # - internal_column_name: ['name_of_column_in_csv', 'label'] if used as additional label (like censoring status)
    # - internal_column_name: ['name_of_column_in_csv', '-'] if just extra information (like age for inspection later)
  drop_cases: # list of lists
    # - ['value_to_drop', 'internal_column_name'] if cases should be dropped based on target label (e.g. label -1)
    # - ['value_to_drop', 'annotation_column'] if cases should be dropped based on additional column (e.g. age 0)
    - ['-1', 'isup']
  # IMAGE PREPROCESSING
  patching:
    n_patches: &n_patches 0 # integer how many patches to cut (if more than possible, additional patches are white)
                             # 0 if no patching is wanted
  augmentation_config:
    rotation: 90.0
    width_shift: 0.1 # float
    height_shift: 0.1 # float
    brightness: 0.05 # float
    horizontal_flip: True # True or False (if random, put true to randomly flip or not)
    vertical_flip: True # True or False (if random, put true to randomly flip or not)
    fill_mode: constant
    cval: 255
  random_augmentation: True # False or True: if the augmentation should be random
  resize_x: &resize_x 256 #256 #
  resize_y: &resize_y 256 #256 #
  resize: [*resize_x, *resize_y]   # [1024, 1024]
  # GENERAL INFORMATION
  channels: *img_channels
  label_type: *label_type
  number_of_classes: *n_classes
  seed: *seed

# ------  ------  ------  ------  ------  ------  ------

model:
  name: m_isup
  base_model: ../models/256_InceptionV3.hdf5
  additional_input: # list, e.g. ['bin0', 'bin1'] to add prediction for relapse in first two years yes+no
  dense_layer_nodes: [32] # list of integers, e.g. [64]
  rnn_layer_nodes: # list of integers, e.g. [256]
  keras_model_params:
    weights: imagenet # None or 'imagenet'
    input_shape: [*resize_x, *resize_y, *img_channels]
  n_patches: *n_patches
  n_classes: *n_classes
  cut_off_layer: 'mixed4'

# ------  ------  ------  ------  ------  ------  ------

training:
  epochs: 2 # int, how many epochs to train (number of communications)
  initial_epoch: 0
  local_epochs: 1 # int, how many epochs to train per communucation round (before merging models again)
  monitor_val: &monitor_val 'val_tf_categorical_accuracy'
  callbacks:
    - name: EarlyStopping
      params:
        patience: 50
        min_delta: 0.02
        monitor: 'val_loss'
        restore_best_weights: False
#    - name: LearningRateScheduler
 #     params:
  #      schedule: 'thirtyepochlower' #'twentyepochlower'
  optimizer: # dict
    name: SGD #Nadam # String for tf.keras optimizer, e.g. 'Adam', 
    params: # list of additional parameters as dict
      - learning_rate: 0.0005
  loss_fn: isup_cce_loss #categorical_crossentropy #
  compile_metrics:
    - TfCategoricalAccuracy
  compile_attributes: {} # dictionary with additional attributes like class_weight
  class_weight: True
  weighted_metrics: False
  aggregation_method: fed_avg


# ------  ------  ------  ------  ------  ------  ------

evaluation:
  metrics:
    - accuracy
    - f1_score
    - kappa